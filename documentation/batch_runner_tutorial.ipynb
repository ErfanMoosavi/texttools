{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f97030a8",
   "metadata": {},
   "source": [
    "\n",
    "# ðŸ“˜ Batch Runner Usage Tutorial\n",
    "\n",
    "Welcome! ðŸŽ‰ This notebook demonstrates how to use the **Batch Runner** in `texttools`.\n",
    "\n",
    "You'll learn:\n",
    "- Setting up dependencies  \n",
    "- Configuring the batch runner  \n",
    "- Running jobs step by step  \n",
    "- Best practices to avoid errors  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e1da08",
   "metadata": {},
   "source": [
    "## ðŸ”§ Best Practices for Setup\n",
    "1- Use a proxy\n",
    "2- Run the code on VPS\n",
    "\n",
    "The first option is better, the data will be locally saved if anything went wrong"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198828fd",
   "metadata": {},
   "source": [
    "## 1. Install & Setup\n",
    "First, make sure you have `texttools` installed:\n",
    "```\n",
    "pip install -U hamta-texttools\n",
    "```\n",
    "\n",
    "Then set your OpenAI (or OpenRouter) API key in a `.env` file:\n",
    "```\n",
    "OPENAI_API_KEY=your_api_key_here\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c1db3c",
   "metadata": {},
   "source": [
    "## 2. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca88795",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from texttools.utils.batch_manager import BatchJobRunner\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685ce948",
   "metadata": {},
   "source": [
    "## 3. Batch Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82493db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutputModel(BaseModel):\n",
    "    output: str\n",
    "\n",
    "\n",
    "def exporting_data(data):\n",
    "    \"\"\"\n",
    "    Produces a structure of the following form from an initial data structure:\n",
    "    [\n",
    "        {\"id\": str, \"content\": str},...\n",
    "    ]\n",
    "    \"\"\"\n",
    "    return data\n",
    "\n",
    "\n",
    "def importing_data(data):\n",
    "    \"\"\"\n",
    "    Takes the output and adds and aggregates it to the original structure.\n",
    "    \"\"\"\n",
    "    return data\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class BatchConfig:\n",
    "    \"\"\"\n",
    "    Configuration for batch job runner.\n",
    "    \"\"\"\n",
    "\n",
    "    system_prompt: str = \"\"\n",
    "    job_name: str = \"\"\n",
    "    input_data_path: str = \"\"\n",
    "    output_data_filename: str = \"\"\n",
    "    model: str = \"gpt-4.1-mini\"\n",
    "    MAX_BATCH_SIZE: int = 100\n",
    "    MAX_TOTAL_TOKENS: int = 2000000\n",
    "    CHARS_PER_TOKEN: float = 2.7\n",
    "    PROMPT_TOKEN_MULTIPLIER: int = 1000\n",
    "    BASE_OUTPUT_DIR: str = \"Data/batch_entity_result\"\n",
    "    import_function: Callable = importing_data\n",
    "    export_function: Callable = exporting_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1dad45",
   "metadata": {},
   "source": [
    "## 4. Running the Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd899f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(\"=== Batch Job Runner ===\")\n",
    "    config = BatchConfig()\n",
    "    runner = BatchJobRunner(config)\n",
    "    runner.run()\n",
    "\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
